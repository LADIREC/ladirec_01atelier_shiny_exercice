geom_node_text(aes(label = mot, size = 2), repel = TRUE) +
geom_node_point(aes(size = freq),
color = '#268bd2') +
scale_size(range = c(1,3)) +
theme(legend.position = 'bottom') +
theme_graph(foreground = 'steelblue',
fg_text_colour = 'white')
library(ggraph)
lire_cooc_ngram_comb[1]
lire_cooc_ngram_comb[1:5]
iter <- text2vec::itoken(lire_cooc_ngram_comb$text,
ids = lire_cooc_ngram_comb$numero_sequence,
progressbar = FALSE)
vocab <- text2vec::create_vocabulary(iter,
ngram = c(ngram_min = 1,
ngram_max = 1)) |>
text2vec::prune_vocabulary(
term_count_min = 5,
term_count_max = Inf)|>
data.table::setDT()
# Pondération TFIDF
tfidf_model <- text2vec::TfIdf$new(smooth_idf = FALSE,
norm = "none",
sublinear_tf = FALSE)
matrice_cosinus <- text2vec::create_dtm(iter,
text2vec::vocab_vectorizer(vocab),
type = "dgCMatrix")
matrice_cosinus[1, matrice_cosinus[1, ]>0]
# Observation du premier docment
matrice_cosinus[1:5, matrice_cosinus[1, ]>0]
iter <- text2vec::itoken(lire_cooc_ngram_comb$text,
ids = lire_cooc_ngram_comb$numero_sequence,
progressbar = FALSE)
vocab <- text2vec::create_vocabulary(iter,
ngram = c(ngram_min = 1,
ngram_max = 1)) |>
text2vec::prune_vocabulary(
term_count_min = 5,
term_count_max = Inf)|>
data.table::setDT()
matrice_cosinus <- text2vec::create_dtm(iter,
text2vec::vocab_vectorizer(vocab),
type = "dgCMatrix")
# Observation des 5 premiers docment
matrice_cosinus[1:5, matrice_cosinus[1, ]>0]
# Pondération de la matrice
dtm_tfidf_initialisaiton <- text2vec::TfIdf$new(smooth_idf = TRUE,
norm = "l1",
sublinear_tf = FALSE)
dtm <- text2vec::create_dtm(iter,
text2vec::vocab_vectorizer(vocab),
type = "dgCMatrix")
# Observation des 5 premiers docment
dtm[1:5, matrice_cosinus[1, ]>0]
# Pondération de la matrice
dtm_tfidf_initialisaiton <- text2vec::TfIdf$new(smooth_idf = TRUE,
norm = "l1",
sublinear_tf = FALSE)
# Transformer la matrice
dtm_tfidf <- dtm_tfidf_initialisaiton$fit_transform(dtm)
# # Observer le premier document
dtm_tfidf[1, dtm_tfidf[1, ] > 0]
# Calculer les distances entre documents vectorisés
system.time(distance_cosine <- 1 - proxyC::simil(x = dtm_tfidf, method = "cosine"))
dim(distance_cosine)
# Création de l'arbre
system.time(hc_clustering <- hclust(d = as.dist(distance_cosine), method = "ward.D"))
# Visualisation de l'arbre
par(mfrow = c(1,1))
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 3, border = "green")
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 10, border = "green")
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 20, border = "green")
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 15, border = "green")
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 12, border = "green")
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 11, border = "green")
# Couper l'arbre à k = 4
group_clust <- cutree(tree = hc_clustering, k = 11)
table_clust <- table(group_clust)
table_clust
# # 1. Convertir le résultat du clustering dans un objet de type dendrogramme ####
hcd <- as.dendrogram(hc_clustering)
clusterCible <- 1
require(wordcloud2)
clusterCible <- 1
which(group_clust == clusterCible)
rangees_selectionner <- which(group_clust == clusterCible)
nrow(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- Matrix::colSums(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- sort(vecteur_sumMots, decreasing = TRUE)[1:30]
df_freq <- data.frame(word = names(vecteur_sumMots), freq = unname(vecteur_sumMots))
wordcloud2::wordcloud2(df_freq, size = 0.4)
clusterCible <- 2
which(group_clust == clusterCible)
rangees_selectionner <- which(group_clust == clusterCible)
nrow(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- Matrix::colSums(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- sort(vecteur_sumMots, decreasing = TRUE)[1:30]
df_freq <- data.frame(word = names(vecteur_sumMots), freq = unname(vecteur_sumMots))
wordcloud2::wordcloud2(df_freq, size = 0.4)
clusterCible <- 3
which(group_clust == clusterCible)
rangees_selectionner <- which(group_clust == clusterCible)
nrow(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- Matrix::colSums(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- sort(vecteur_sumMots, decreasing = TRUE)[1:30]
df_freq <- data.frame(word = names(vecteur_sumMots), freq = unname(vecteur_sumMots))
wordcloud2::wordcloud2(df_freq, size = 0.4)
groupe_nuage <- function(x) {
clusterCible <- x
rangees_selectionner <- which(group_clust == clusterCible)
vecteur_sumMots <- Matrix::colSums(dtm_tfidf[rangees_selectionner, ])
vecteur_sumMots <- sort(vecteur_sumMots, decreasing = TRUE)[1:30]
df_freq <- data.frame(word = names(vecteur_sumMots), freq = unname(vecteur_sumMots))
wordcloud2::wordcloud2(df_freq, size = 0.4)
}
groupe_nuage(6)
groupe_nuage(5)
groupe_nuage(10)
groupe_nuage(11)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
# Fonction pour la visualisation des clusters sous forme de tableau de spécificité
quanteda_dtm <- quanteda::as.dfm(dtm)
#Fonction de visualisation
specificite <- function(x) {
clusterCible <- x
specificites_mots_culster_cible <- textstat_keyness(x = quanteda_dtm,
target = group_clust == clusterCible,
measure = "chi2", sort = TRUE)
p <- textplot_keyness(x = specificites_mots_culster_cible, n = 25, margin = 0.5,
color = c("blue", "red"), show_legend = FALSE)
p + ggplot2::labs(title = paste("Spécificités lexicales des documents du cluster N. : ",
as.character(clusterCible)), x = "Score spécificité")
}
specificite(11)
specificite(11)
specificite(1)
specificite(2)
specificite(3)
p <- textplot_keyness(x = specificites_mots_culster_cible, n = 25, margin = 0.5,
color = c("deepblue", "red"), show_legend = FALSE)
specificite <- function(x) {
clusterCible <- x
specificites_mots_culster_cible <- textstat_keyness(x = quanteda_dtm,
target = group_clust == clusterCible,
measure = "chi2", sort = TRUE)
p <- textplot_keyness(x = specificites_mots_culster_cible, n = 25, margin = 0.5,
color = c("deepblue", "red"), show_legend = FALSE)
p + ggplot2::labs(title = paste("Spécificités lexicales des documents du cluster N. : ",
as.character(clusterCible)), x = "Score spécificité")
}
specificite(1)
#Fonction de visualisation
specificite <- function(x) {
clusterCible <- x
specificites_mots_culster_cible <- textstat_keyness(x = quanteda_dtm,
target = group_clust == clusterCible,
measure = "chi2", sort = TRUE)
p <- textplot_keyness(x = specificites_mots_culster_cible, n = 25, margin = 0.5,
color = c("blue", "red"), show_legend = FALSE)
p + ggplot2::labs(title = paste("Spécificités lexicales des documents du cluster N. : ",
as.character(clusterCible)), x = "Score spécificité")
}
specificite(1)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)][
,.,by=annee_publication
][order(N, decreasing = TRUE)]
groupe_nuage <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)][
,.,by=annee_publication
][order(N, decreasing = TRUE)]
}
# Fonction pour la visualisation des clusters sous forme de nuages
groupe_nuage <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
vecteur_sumMots <- Matrix::colSums(dtm_tfidf[rangees_selectionnees, ])
vecteur_sumMots <- sort(vecteur_sumMots, decreasing = TRUE)[1:30]
df_freq <- data.frame(word = names(vecteur_sumMots), freq = unname(vecteur_sumMots))
wordcloud2::wordcloud2(df_freq, size = 0.4)
}
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)][
,.,by=annee_publication
][order(N, decreasing = TRUE)]
}
obs_corpus(5)
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)][
,.N,by=annee_publication
][order(N, decreasing = TRUE)]
}
obs_corpus(5)
# Observation des titres de romans appartenant à un cluster
x=1
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)]
sous_corpus_selectionne[,.N,by=annee_publication][order(N, decreasing = TRUE)]
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)]
sous_corpus_selectionne[1:50,,by=annee_publication][order(N, decreasing = TRUE)]
}
obs_corpus(5)
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(numero_sequence, auteur, titre, editeur, annee_publication)]
sous_corpus_selectionne[1:50,,by=annee_publication][order(annee_publication, decreasing = TRUE)]
}
obs_corpus(5)
# Observation des titres de romans appartenant à un cluster
x=1
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(titre, editeur, annee_publication)]
sous_corpus_selectionne[1:50,,by=annee_publication][order(annee_publication, decreasing = TRUE)]
}
obs_corpus(5)
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(titre, editeur, annee_publication)]
sous_corpus_selectionne[1:50,,by=editeur][order(annee_publication, decreasing = TRUE)]
}
obs_corpus(5)
plot(as.phylo(hc_clustering), main = NULL, type = "unrooted", cex = 0.5, no.margin = TRUE, show.tip.label = FALSE)
# # Visualisation de l'arbre
# plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
# rect.hclust(tree = hc_clustering, k = 11, border = "green")
if(!"ape" %in% rownames(installed.packages())) {install.packages("ape")}
plot(as.phylo(hc_clustering), main = NULL, type = "unrooted", cex = 0.5, no.margin = TRUE, show.tip.label = FALSE)
# # Visualisation de l'arbre
plot(hc_clustering, main = "Regroupement hiérarchique", xlab = NULL, ylab="Hauteur", labels = FALSE)
rect.hclust(tree = hc_clustering, k = 11, border = "green")
plot(as.phylo(hc_clustering), main = NULL, type = "unrooted", cex = 0.5, no.margin = TRUE, show.tip.label = FALSE)
if(!('text2vec' %in% rownames(installed.packages()))){
install.packages('text2vec')}
if(!('magrittr' %in% rownames(installed.packages()))){
install.packages('magrittr')}
if(!('udpipe' %in% rownames(installed.packages()))){
install.packages('udpipe')}
if(!('ggplot2' %in% rownames(installed.packages()))){
install.packages('ggplot2')}
if(!('Matrix' %in% rownames(installed.packages()))){
install.packages('Matrix')}
if(!('data.table' %in% rownames(installed.packages()))){
install.packages('data.table')}
if(!('ggraph' %in% rownames(installed.packages()))){
install.packages('ggraph')}
if(!('tidygraph' %in% rownames(installed.packages()))){
install.packages('tidygraph')}
if(!('graphlayouts' %in% rownames(installed.packages()))){
install.packages('graphlayouts')}
if(!('igraph' %in% rownames(installed.packages()))){
install.packages('igraph')}
if(!('tufte' %in% rownames(installed.packages()))){
install.packages('tufte')}
if(!('proxyC' %in% rownames(installed.packages()))){
install.packages('proxyC')}
if(!('reshape2' %in% rownames(installed.packages()))){
install.packages('reshape2')}
libs <- c( "stringr", "dplyr", "tidytext", "lsa", "tm", "data.table", "microbenchmark",
"text2vec", "magrittr", "udpipe", "ggplot2", "Matrix", "ggraph", "tidygraph",
"graphlayouts", "tufte", "proxyC", "reshape2")
lapply(libs, require, character.only = TRUE)
plot(as.phylo(hc_clustering), main = NULL, type = "unrooted", cex = 0.5, no.margin = TRUE, show.tip.label = FALSE)
obs_corpus <- function(x) {
clusterCible <- x
rangees_selectionnees <- which(group_clust == clusterCible)
sous_corpus_selectionne <- lire[numero_sequence %in% names(rangees_selectionnees), .(titre, editeur, annee_publication)]
sous_corpus_selectionne[1:50,,by=editeur][order(annee_publication, decreasing = TRUE)]
}
obs_corpus(5)
visualisation <- function(x){
groupe_nuage(x)
specificite(x)
obs_corpus(x)
}
visualisation(1)
library(dendextend)
library(plotly)
dend <- color_branches(hc_clustering, 5)
p <- ggplot(dend, horiz=T, offset_labels = -3)
ggplotly(p)
gc()
dtm_tfidf[1]
dtm_tfidf[1, dtm_tfidf[1,]>0]
dtm_tfidf[1:5, dtm_tfidf[1,]>0]
rownames(dtm_tfidf[1:5, dtm_tfidf[1,]>0])
# Calculer les distances entre documents vectorisés
distance_cosine <- 1 - proxyC::simil(x = dtm_tfidf[1:50], method = "cosine")
rownames(dtm_tfidf)[1]
# ================================================= À partir d'ici, le travail devra se faire du côté du serveur
lire[1:50, c("numero_sequence")]
# ================================================= À partir d'ici, le travail devra se faire du côté du serveur
unlist(lire[1:50, c("numero_sequence")])
dtm_tfidf_filtree <- rownames(dtm_tfidf %in% unlist(lire[1:50, c("numero_sequence")]))
# ================================================= À partir d'ici, le travail devra se faire du côté du serveur
lire$numero_sequence[1:50]
dtm_tfidf_filtree <- rownames(dtm_tfidf %in% lire$numero_sequence[1:50)
dtm_tfidf_filtree <- rownames(dtm_tfidf %in% lire$numero_sequence[1:50])
lire$numero_sequence[1:50]
rownames(dtm_tfidf)[1]
dtm_tfidf_filtree <- rownames(dtm_tfidf %in% as.character(lire$numero_sequence[1:50]))
as.character(lire$numero_sequence[1:50])
dtm_tfidf_filtree <- dtm_tfidf[, dtm_tfidf[rownames(dtm_tfidf %in% as.character(lire$numero_sequence[1:5]))]]
dtm_tfidf[, dtm_tfidf[rownames(dtm_tfidf) %in% as.character(lire$numero_sequence[1:5])]]
dtm_tfidf_filtree <- dtm_tfidf[, dtm_tfidf[rownames(dtm_tfidf) %in% as.character(lire$numero_sequence[1:5])]]
# Calculer les distances entre documents vectorisés
distance_cosine <- 1 - proxyC::simil(x = dtm_tfidf_filtree, method = "cosine")
# Création de l'arbre
hc_clustering <- hclust(d = as.dist(distance_cosine), method = "ave")
dend <- color_branches(hc_clustering, 5)
shiny::runApp('Dropbox/ShinyRomans@lireDashboard/dashboard/20220106_PB_RomansAlireViz')
runApp('Dropbox/ShinyRomans@lireDashboard/dashboard/20220106_PB_RomansAlireViz')
load("/Users/pascalbrissette/Downloads/givenNamesDB_authorships.rda")
View(givenNamesDB_authorships)
runApp('Dropbox/ShinyRomans@lireDashboard/dashboard/20220106_PB_RomansAlireViz')
runApp('Dropbox/ShinyRomans@lireDashboard/dashboard/20220106_PB_RomansAlireViz')
runApp('Dropbox/ShinyRomans@lireDashboard/dashboard/20220106_PB_RomansAlireViz')
24*8
shiny::runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
View(gars)
View(gars)
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
View(gars)
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
library(DT)
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
library(ggplot2)
mtcars
data("mtcars")
setDT(mtcars)
library(data.table)
setDT(mtcars)
mtcars
install.packages("xlsx")
livres <- readxl::read_xlsx("Downloads/pdrpretslivres.xlsx")
View(livres)
livres
str(livres)
library(data.table)
topo <- fread("Downloads/toponymes_officiels.csv")
topo
shiny::runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
graph2 <- ggplot(total, aes(x=annee, y=nombre))+
geom_point(colour = "blue")+geom_line(aes(x=annee, y=nombre))+
theme(axis.text.x = element_text(vjust = 0.5, hjust=1))+
theme(axis.title.x = element_blank(),
axis.title.y = element_blank())+
ggtitle("Distribution chronologique du prénom", paste0("«", x, "»"))
source("~/Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo/20220124_basic_script.R", echo=TRUE)
source("~/Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo/20220124_basic_script.R", echo=TRUE)
runApp('Dropbox/ShinyRomans@lireDashboard/2022_PB_AtelierDemo')
remove.packages("data.table", lib="~/Library/R/x86_64/4.1/library")
installation_extensions <- function(extensions){
if(!as.character(extensions) %in% as.character(rownames(installed.packages()))){
install.packages(as.character(extensions))
}
}
extensions <- c("shiny", "data.table", "ggplot2")
lapply(extensions, installation_extensions)
lapply(extensions, require, character.only = TRUE)
# Importation des données sous la forme d'une data.table
toponymes <- fread("toponymes_officiels.csv")
setwd(getwd())
# Importation des données sous la forme d'une data.table
toponymes <- fread("toponymes_officiels.csv")
setwd("~/Dropbox/ShinyRomans@lireDashboard/2022AtelierShinyExercice")
# Importation des données sous la forme d'une data.table
toponymes <- fread("toponymes_officiels.csv")
str(toponymes)
View(toponymes)
unique(toponymes$Origine_linguistique)
runApp()
unique(toponymes$Origine_linguistique)
runApp()
unique(toponymes$Origine_linguistique)
runApp()
runApp()
#   }
# }
# extensions <- c("shiny", "data.table", "ggplot2")
# lapply(extensions, installation_extensions)
# lapply(extensions, require, character.only = TRUE)
#
# # Importation des données sous la forme d'une data.table
# toponymes <- fread("toponymes_officiels.csv")
# str(toponymes)
# unique(toponymes$Origine_linguistique)
library(shiny)
library(data.table)
choix_langues <- c("Français", "Inuktitut")
runApp()
toponymes[Origine_linguistique %in% choix_langues, ]
x <- toponymes[Origine_linguistique %in% choix_langues, ]
ggplot(x, aes(x=Origine_linguistique))+
geom_bar()+
coord_flip()
runApp()
runApp()
runApp()
#   }
# }
# extensions <- c("shiny", "data.table", "ggplot2")
# lapply(extensions, installation_extensions)
# lapply(extensions, require, character.only = TRUE)
#
# # Importation des données sous la forme d'une data.table
# toponymes <- fread("toponymes_officiels.csv")
# str(toponymes)
# unique(toponymes$Origine_linguistique)
library(shiny)
#   }
# }
# extensions <- c("shiny", "data.table", "ggplot2")
# lapply(extensions, installation_extensions)
# lapply(extensions, require, character.only = TRUE)
#
# # Importation des données sous la forme d'une data.table
# toponymes <- fread("toponymes_officiels.csv")
# str(toponymes)
# unique(toponymes$Origine_linguistique)
install.packages("shiny")
install.packages("shiny")
library(shiny)
library(data.table)
runApp()
install.packages("shiny")
shiny::runApp()
library(ggplot2)
runApp()
runApp()
toponymes <- fread("toponymes_officiels.csv")
str(toponymes)
unique(toponymes$Origine_linguistique)
choix_langues <- c("Français", "Inuktitut")
x <- toponymes[Origine_linguistique %in% choix_langues]
ggplot(x, aes(x=Origine_linguistique))+
geom_bar()+
coord_flip()
runApp()
# Importation des données sous la forme d'une data.table
toponymes <- read.csv("toponymes_officiels.csv")
unique(toponymes$Origine_linguistique)
unique(toponymes$Origine_linguistique)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
unique(toponymes$Origine_linguistique)
runApp()
runApp()
runApp()
runApp()
runApp('~/Dropbox/ShinyRomans@lireDashboard/dashboard/20220106_PB_RomansAlireViz')
